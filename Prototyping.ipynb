{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82467dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "120a5969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35fc7f44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# matches = re.match('var La=\\[(?:\"([a-z]+)\",?)+\\]', wordle_js)\n",
    "def extract_wordlist(name):\n",
    "    raw_list = re.findall(fr'{name}=\\[([a-z\",]+)\\]', wordle_js)[0]\n",
    "    return raw_list.replace('\"', '').split(',')\n",
    "\n",
    "solutions_str = extract_wordlist('La')\n",
    "guesses_str   = extract_wordlist('Ta') + solutions_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abaf7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(word):\n",
    "    return np.array([ord(c) - ord('a') for c in word])\n",
    "\n",
    "def decode(word_vector):\n",
    "    return ''.join(chr(ord('a') + c) for c in word_vector)\n",
    "\n",
    "solutions = np.stack([encode(word) for word in solutions_str])\n",
    "guesses   = np.stack([encode(word) for word in guesses_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2eecf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess acccb for bccca scored correctly.\n",
      "Guess aaaab for baaaa scored correctly.\n",
      "Guess abcda for abcde scored correctly.\n",
      "Guess cbada for abcde scored correctly.\n",
      "Guess cbada for abcde scored correctly.\n",
      "Guess zymic for could scored correctly.\n"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def score_guess(guess, solution):\n",
    "    green  = (guess == solution)\n",
    "    \n",
    "    # Effectively mask out green numbers\n",
    "    solution = solution + jnp.where(green, 100, 0)\n",
    "    guess    = guess + jnp.where(green, 1000, 0)\n",
    "        \n",
    "    def is_yellow(i):\n",
    "        return (jnp.cumsum(guess == guess[i])[i] <= jnp.sum(solution == guess[i]))\n",
    "    \n",
    "    yellow = jax.vmap(is_yellow)(jnp.arange(5))\n",
    "    return jnp.where(green,  2,\n",
    "           jnp.where(yellow, 1,\n",
    "                             0))\n",
    "\n",
    "\n",
    "def fmt_score(score):\n",
    "    return ''.join('✕~✓'[i] for i in score)\n",
    "\n",
    "## Test cases\n",
    "def test(guess, solution, expected_score):\n",
    "    score = score_guess(encode(guess), encode(solution))\n",
    "    if np.all(score == np.asarray(expected_score)):\n",
    "        print(f'Guess {guess} for {solution} scored correctly.')\n",
    "    else:\n",
    "        print(f'Guess {guess} for {solution} scored '\n",
    "              f'{fmt_score(score)}, expected {fmt_score(expected_score)}!')\n",
    "\n",
    "test('acccb', 'bccca', [1,2,2,2,1])\n",
    "test('aaaab', 'baaaa', [1,2,2,2,1])\n",
    "test('abcda', 'abcde', [2,2,2,2,0])\n",
    "test('cbada', 'abcde', [1,2,1,2,0])\n",
    "test('cbada', 'abcde', [1,2,1,2,0])\n",
    "test('zymic', 'could', [0,0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee26400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_functions():\n",
    "    def encoder(guess, score):\n",
    "        letter_emb = hk.Embed(26, 112, name='letter_emb')(guess)\n",
    "        guess_emb  = hk.Embed(26,  16, name='guess_emb')(score)\n",
    "        x = jnp.concatenate([letter_emb, guess_emb], axis=-1)\n",
    "        x = rearrange(x, 'batch letter dim -> batch (letter dim)')\n",
    "        return hk.Sequential([\n",
    "            hk.Linear(1024, name='enc1'), jax.nn.relu,\n",
    "            hk.Linear(1024, name='enc2'), jax.nn.relu,\n",
    "            hk.Linear(1024, name='enc3'),\n",
    "        ])(x)\n",
    "        \n",
    "    def actor(current_information):\n",
    "        features = hk.Sequential([\n",
    "            hk.Linear(1024), jax.nn.relu,\n",
    "            hk.Linear(1024), jax.nn.relu,\n",
    "        ])(current_information)\n",
    "        guess_logits    = hk.Linear(len(guesses))(features)\n",
    "        expected_reward = hk.Linear(len(guesses))(features)\n",
    "        return guess_logits, expected_reward\n",
    "        \n",
    "    def init(guess, score):\n",
    "        info = encoder(guess, score)\n",
    "        actions = actor(info)\n",
    "        return actions\n",
    "\n",
    "    return init, (encoder, actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa2daaac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlatMap({\n",
       "  'enc1': FlatMap({'b': (1024,), 'w': (640, 1024)}),\n",
       "  'enc2': FlatMap({'b': (1024,), 'w': (1024, 1024)}),\n",
       "  'enc3': FlatMap({'b': (1024,), 'w': (1024, 1024)}),\n",
       "  'guess_emb': FlatMap({'embeddings': (26, 16)}),\n",
       "  'letter_emb': FlatMap({'embeddings': (26, 112)}),\n",
       "  'linear': FlatMap({'b': (1024,), 'w': (1024, 1024)}),\n",
       "  'linear_1': FlatMap({'b': (1024,), 'w': (1024, 1024)}),\n",
       "  'linear_2': FlatMap({'b': (12972,), 'w': (1024, 12972)}),\n",
       "  'linear_3': FlatMap({'b': (12972,), 'w': (1024, 12972)}),\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unpack_without_apply_rng(multitransformed):\n",
    "    funs = multitransformed.apply\n",
    "    def apply_without_rng(fun):\n",
    "        def inner(params, *args, **kwargs):\n",
    "            return fun(params, None, *args, **kwargs)\n",
    "        return inner\n",
    "    \n",
    "    return jax.tree_map(apply_without_rng, funs)\n",
    "\n",
    "net = hk.multi_transform(build_functions)\n",
    "rng = jax.random.PRNGKey(42)\n",
    "\n",
    "guess = jnp.ones([7, 5], dtype=jnp.uint8)\n",
    "score = jnp.ones([7, 5], dtype=jnp.uint8)\n",
    "params = net.init(rng, guess, score)\n",
    "encoder, actor = unpack_without_apply_rng(net)\n",
    "opt = optax.adam(1e-1)\n",
    "opt_state = opt.init(params)\n",
    "\n",
    "jax.tree_map(lambda x: x.shape, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97a322dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@partial(jax.vmap, in_axes=[-1, None], out_axes=-1)\n",
    "@partial(jax.vmap, in_axes=[None, 0], out_axes=0)\n",
    "def select_guess(guesses, idx):\n",
    "    return guesses[idx]\n",
    "\n",
    "@jax.jit\n",
    "def training_step(key, solutions, opt_state, params):\n",
    "    def calculate_loss(θ):\n",
    "        B = solutions.shape[0]\n",
    "        information = jnp.zeros([B, 1024])\n",
    "        \n",
    "        evaluations = []\n",
    "        scores = []\n",
    "        expected_rewards = []\n",
    "        \n",
    "        for i in range(6):\n",
    "            guess_logits, evaluation = actor(θ, information)\n",
    "            guess_idx = jax.random.categorical(key, guess_logits)\n",
    "            guess = select_guess(guesses, guess_idx)\n",
    "            evaluations.append(jnp.take_along_axis(evaluation, guess_idx.reshape(-1, 1), axis=-1))\n",
    "            \n",
    "            expected_rewards.append(jnp.sum(jax.nn.softmax(guess_logits, axis=-1) *\n",
    "                                      jax.lax.stop_gradient(evaluation), axis=-1))\n",
    "            \n",
    "            score = jax.vmap(score_guess)(guess, solutions)\n",
    "            scores.append(score)\n",
    "            information = information + encoder(θ, guess, score)\n",
    "\n",
    "        scores = jnp.stack(scores, axis=1)\n",
    "        solved = jnp.all(scores == 2, axis=-1)\n",
    "        reward = scores.sum(axis=[1, 2]) + 100 * solved.sum(axis=1)\n",
    "        critic_loss = sum(jnp.mean(jnp.abs(ev - reward)) for ev in evaluations)\n",
    "        expected_reward = jnp.mean(jnp.stack(expected_rewards))\n",
    "        actor_loss = -expected_reward\n",
    "        \n",
    "        return critic_loss + actor_loss, dict(\n",
    "            critic_loss=critic_loss,\n",
    "            actor_loss=actor_loss,\n",
    "            expected_reward=expected_reward,\n",
    "            actual_reward=jnp.mean(reward),\n",
    "            pct_solved=jnp.mean(solved),\n",
    "        )\n",
    "    \n",
    "    grads, metrics = jax.grad(calculate_loss, has_aux=True)(params)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    return metrics, opt_state, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "616798e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "training_key = jax.random.PRNGKey(0)\n",
    "\n",
    "def train_epoch(key, opt_state, params):\n",
    "    key, subkey = jax.random.split(key)\n",
    "    batch_data = jax.random.permutation(key, solutions, axis=-1)\n",
    "    N = batch_data.shape[0]\n",
    "    batch_data = batch_data[:(N//batch_size)*batch_size]\n",
    "    all_metrics = []\n",
    "    for batch in rearrange(batch_data, '(N B) ... -> N B ...', B=64):\n",
    "        metrics, opt_state, params = training_step(training_key, batch, opt_state, params)\n",
    "        all_metrics.append(jax.tree_map(float, metrics))\n",
    "    return all_metrics, opt_state, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4323942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.414496527777779 0.0\n",
      "9.379340277777779 0.0\n",
      "9.07595486111111 0.0\n",
      "7.794270833333333 0.0\n",
      "7.794270833333333 0.0\n",
      "7.794270833333333 0.0\n",
      "8.24826388888889 0.0\n",
      "8.28689236111111 0.0\n",
      "8.26953125 0.0\n",
      "9.58029513888889 0.0\n",
      "9.6953125 0.0\n",
      "9.6953125 0.0\n",
      "9.6953125 0.0\n",
      "9.6953125 0.0\n",
      "9.807725694444445 0.0\n",
      "10.207899305555555 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n",
      "10.1796875 0.0\n"
     ]
    }
   ],
   "source": [
    "epochs = []\n",
    "for epoch in range(200):\n",
    "    metrics, opt_state, params = train_epoch(jax.random.PRNGKey(0), opt_state, params)\n",
    "    epoch_metrics = pd.DataFrame(metrics).mean()\n",
    "    print(epoch_metrics['actual_reward'], epoch_metrics['pct_solved'])\n",
    "    epochs.append(epoch_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb567ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_metrics = pd.concat([pd.DataFrame(epoch).mean() for epoch in epochs], axis=1).T\n",
    "plt.plot(epoch_metrics.actor_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4679953",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metrics)\n",
    "plt.plot(df['actual_reward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6220a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d213d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
